# -*- coding: utf-8 -*-
"""MLT_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uJQPFr5cWaJomShGIBUQYN38pCoZkv2n

# **Project Machine Learning #1 - PUTRA ADE NIRADA**

#Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.combine import SMOTEENN
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

# %matplotlib inline

"""#Load Dataset"""

df = pd.read_csv("Default_Fin.csv")

df.head()

df.info()

"""#**Exploratory Data Analysis (EDA)**

##Analisis Deskriptif
"""

df.describe(include='all')

df.isnull().sum()

duplicated  = df.duplicated().sum()
print(f"Data Duplicat: {duplicated}")

"""##Outliers

###Identifikasi Awal
"""

num_cols  = df.select_dtypes(include='number').columns

for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot {col}')
    plt.show()

"""###Penanganan Outliers"""

num_cols = num_cols.drop('Defaulted?')

# Hitung Q!, Q3 dan IQR hanya untuk kolom numerikal
Q1 = df[num_cols].quantile(0.25)
Q3 = df[num_cols].quantile(0.75)
IQR = Q3 - Q1

# Buat filter untuk menghapus baris yang mengandung outlier di kolom numerikal
filters_outliers = ~((df[num_cols] < (Q1 - 1.0 * IQR)) |
                     (df[num_cols] > (Q3 + 1.0 * IQR))).any(axis=1)

# Terapkan filter ke dataset asli (termasuk kolom non-numerikal)
df = df[filters_outliers]

# Cek ukuran dataset setelah outliers dihapus
df.shape

for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.boxplot(x=df[col])
    plt.title(f'Boxplot {col}')
    plt.show()

"""## Penghapusan Fitur yang Tidak Relevan"""

df = df.drop(columns=['Index'])

"""##Visualisasi Distribusi"""

num_cols  = df.select_dtypes(include='number').columns
for col in num_cols:
    plt.figure(figsize=(6,4))
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribusi {col}')
    plt.show()

"""##Coorelation Heatmap"""

num_features = df.select_dtypes(include='number').columns.to_list()
cor = df[num_features].corr().round(2)
sns.heatmap(cor, annot=True, cmap='coolwarm')
plt.show()

"""##Insight

* **Insight 1:** Mayoritas individu dalam dataset memiliki pekerjaan, dan kemungkinan gagal bayar lebih rendah pada individu yang bekerja.
* **Insight 2:** Saldo bank dan gaji tahunan tampaknya memiliki peran penting dalam menentukan kemungkinan gagal bayar.
* **Insight 3:** Dataset sangat tidak seimbang dari sisi target (`Defaulted?`), sehingga perlu penanganan khusus seperti resampling atau pemilihan metrik evaluasi yang tepat.

# **Data Preparation**

##Train-Test Split Data
"""

X = df.drop('Defaulted?', axis=1)
y = df['Defaulted?']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("\n--- Distribusi Kelas Setelah Pembagian Data ---")
print("Distribusi kelas di Training Set:")
print(y_train.value_counts())
print(f"Proporsi kelas gagal bayar di Training Set: {y_train.value_counts(normalize=True)[1]:.2%}")
print("\nDistribusi kelas di Test Set:")
print(y_test.value_counts())
print(f"Proporsi kelas gagal bayar di Test Set: {y_test.value_counts(normalize=True)[1]:.2%}")

"""##Resampling dengan SMOTEENN pada Training Set"""

sme = SMOTEENN(random_state=42)

X_train_resampled, y_train_resampled = sme.fit_resample(X_train, y_train)

print("Distribusi kelas di Training Set setelah SMOTEENN:")
print(y_train_resampled.value_counts())

"""##Standard Scaling"""

scaler = StandardScaler()

# Fit scaler hanya pada training set (yang sudah di-resample) dan transform.
X_train_scaled = scaler.fit_transform(X_train_resampled)

# Transform test set menggunakan scaler yang sama yang di-fit pada training set.
X_test_scaled = scaler.transform(X_test)

"""# Modeling"""

models = {
    "KNN" : KNeighborsClassifier(n_neighbors=15),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
}

results = {}

# Training & Evaluasi Model
for name, model in models.items():
    # Training
    model.fit(X_train_scaled, y_train_resampled)

    # Prediksi
    y_pred = model.predict(X_test_scaled)

    # Evaluasi
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)
    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)

    # Simpan hasil evaluasi
    results[name] = {
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1_score": f1,
        "confusion_matrix": confusion_matrix(y_test, y_pred),
        "classification_report": classification_report(y_test, y_pred, zero_division=0)
    }

"""# Evaluation"""

# Tampilkan hasil evaluasi
for name, metrics in results.items():
    print(f"\nðŸ“Œ Model: {name}")
    print(f"Accuracy       : {metrics['accuracy']:.4f}")
    print(f"Precision      : {metrics['precision']:.4f}")
    print(f"Recall         : {metrics['recall']:.4f}")
    print(f"F1 Score       : {metrics['f1_score']:.4f}")
    print("Confusion Matrix:\n", metrics['confusion_matrix'])
    print("Classification Report:\n", metrics['classification_report'])
    print("="*60)